{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Installation and unzipping and importing libraries**"
      ],
      "metadata": {
        "id": "D1Jy3E_6V9l6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9O6MwjSVtDr",
        "outputId": "22f22bba-e485-4dc2-e6da-01aab4ce1b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Archive:  /content/ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3163765 sha256=10dba556a9213d759ad03eb6fa173809cecc43c1890bee72b13e1ebe3005b9f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas matplotlib seaborn\n",
        "!unzip /content/ml-100k.zip\n",
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate, train_test_split , GridSearchCV\n",
        "from surprise import accuracy\n",
        "from surprise import SVD\n",
        "from surprise import dump"
      ],
      "metadata": {
        "id": "eXL0_kuZWC86"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train**"
      ],
      "metadata": {
        "id": "GEB3n2VHcEAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_number = 5\n",
        "path_to_datasets= \"/content/ml-100k/\"\n",
        "# Load user data\n",
        "users_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "users = pd.read_csv(f'{path_to_datasets}u.user', sep='|', names=users_cols, encoding='latin-1')\n",
        "\n",
        "# Load ratings data\n",
        "ratings_cols = ['user_id', 'movie_id' ,'rating', 'unix_timestamp']\n",
        "ratings = pd.read_csv(f'{path_to_datasets}u{dataset_number}.base', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
        "\n",
        "# Load movies data\n",
        "movies_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL'] + ['genre_' + str(i) for i in range(19)]\n",
        "movies = pd.read_csv(f'{path_to_datasets}u.item', sep='|', names=movies_cols, encoding='latin-1', usecols=range(24))\n",
        "\n",
        "df = ratings.merge(movies, left_on='movie_id', right_on='movie_id', how='left')\n",
        "\n",
        "df = df[['user_id', 'title', 'rating']]\n",
        "\n",
        "\n",
        "reader = Reader(rating_scale=(1,5))\n",
        "data = Dataset.load_from_df(df, reader)\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.01)\n",
        "\n",
        "model = SVD(n_factors=200)\n",
        "model.fit(train)\n",
        "\n",
        "# Save the model to a file\n",
        "model_filename = f\"surprise_svd_model{dataset_number}\"\n",
        "dump.dump(model_filename, predictions=None, algo=model)"
      ],
      "metadata": {
        "id": "JueZ1_bFcHun"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read The for test"
      ],
      "metadata": {
        "id": "c_gwLQa0W_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_number = 1\n",
        "path_to_datasets= \"/content/ml-100k/\"\n",
        "# Load user data\n",
        "users_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "users = pd.read_csv(f'{path_to_datasets}u.user', sep='|', names=users_cols, encoding='latin-1')\n",
        "\n",
        "# Load ratings data\n",
        "ratings_cols = ['user_id', 'movie_id' ,'rating', 'unix_timestamp']\n",
        "ratings = pd.read_csv(f'{path_to_datasets}u{dataset_number}.test', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
        "\n",
        "# Load movies data\n",
        "movies_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL'] + ['genre_' + str(i) for i in range(19)]\n",
        "movies = pd.read_csv(f'{path_to_datasets}u.item', sep='|', names=movies_cols, encoding='latin-1', usecols=range(24))\n",
        "\n",
        "df = ratings.merge(movies, left_on='movie_id', right_on='movie_id', how='left')\n",
        "\n",
        "df = df[['user_id', 'title', 'rating']]"
      ],
      "metadata": {
        "id": "xsCdNaNVXB1W"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the saved model\n",
        "\n"
      ],
      "metadata": {
        "id": "SotOen0cWWba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reader = Reader(rating_scale=(1,5))\n",
        "data = Dataset.load_from_df(df, reader)"
      ],
      "metadata": {
        "id": "NjdsndX7Wk2y"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data, test_size=0.99)"
      ],
      "metadata": {
        "id": "c_NqGek5Whi4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_filename = 'surprise_svd_model1'\n",
        "\n",
        "loaded_model = dump.load(model_filename)[1]\n",
        "predictions = loaded_model.test(test)\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ungCf9NMWFkH",
        "outputId": "a81c319e-1174-4a3d-8532-4098729b74dc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9560059948040892"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **evaluation fuction**"
      ],
      "metadata": {
        "id": "XcX0AaKaZ03q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation2(dataset_number):\n",
        "  path_to_datasets= \"/content/ml-100k/\"\n",
        "  # Load user data\n",
        "  users_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "  users = pd.read_csv(f'{path_to_datasets}u.user', sep='|', names=users_cols, encoding='latin-1')\n",
        "\n",
        "  # Load ratings data\n",
        "  ratings_cols = ['user_id', 'movie_id' ,'rating', 'unix_timestamp']\n",
        "  ratings = pd.read_csv(f'{path_to_datasets}u{dataset_number}.test', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
        "\n",
        "  # Load movies data\n",
        "  movies_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL'] + ['genre_' + str(i) for i in range(19)]\n",
        "  movies = pd.read_csv(f'{path_to_datasets}u.item', sep='|', names=movies_cols, encoding='latin-1', usecols=range(24))\n",
        "\n",
        "  df = ratings.merge(movies, left_on='movie_id', right_on='movie_id', how='left')\n",
        "\n",
        "  df = df[['user_id', 'title', 'rating']]\n",
        "\n",
        "\n",
        "  reader = Reader(rating_scale=(1,5))\n",
        "  data = Dataset.load_from_df(df, reader)\n",
        "  train, test = train_test_split(data, test_size=0.99)\n",
        "  model_filename = f\"surprise_svd_model{dataset_number}\"\n",
        "\n",
        "  loaded_model = dump.load(model_filename)[1]\n",
        "  predictions = loaded_model.test(test)\n",
        "  RMSE = accuracy.rmse(predictions)\n",
        "  print(f\"of dataset {dataset_number}\")\n",
        "  return RMSE\n",
        "x=evaluation2(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v25TA-GGZ0dK",
        "outputId": "b9e7cd83-d41b-440e-d7f3-e4c3aab54e0d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9387\n",
            "of dataset 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset1 RMSE = 0.9566\n",
        "\n",
        "dataset2 RMSE = 0.9418\n",
        "\n",
        "dataset3 RMSE = 0.9364\n",
        "\n",
        "dataset4 RMSE = 0.9387\n",
        "\n",
        "dataset5 RMSE = 0.9385\n"
      ],
      "metadata": {
        "id": "ke-VlGnpddvu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iROiCNyBYnRV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}